{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Input, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phrase builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_data_true', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    text = text.replace('\\ufeff', '')  # убираем первый невидимый символ\n",
    "    text = re.sub(r'[^А-я ]', '', text)  # заменяем все символы кроме кириллицы на пустые символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'о': 2, 'е': 3, 'т': 4, 'и': 5, 'а': 6, 'н': 7, 'с': 8, 'в': 9, 'р': 10, 'м': 11, 'л': 12, 'ь': 13, 'д': 14, 'п': 15, 'у': 16, 'ы': 17, 'з': 18, 'я': 19, 'б': 20, 'ч': 21, 'к': 22, 'й': 23, 'ж': 24, 'г': 25, 'ш': 26, 'х': 27, 'ю': 28, 'ц': 29, 'щ': 30, 'э': 31, 'ф': 32, 'ъ': 33}\n"
     ]
    }
   ],
   "source": [
    "# парсим текст, как последовательность символов\n",
    "num_characters = 34  # 33 буквы + пробел\n",
    "tokenizer = Tokenizer(num_words=num_characters, char_level=True)  # токенизируем на уровне символов\n",
    "tokenizer.fit_on_texts([text])  # формируем токены на основе частотности в нашем тексте\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_chars = 6\n",
    "data = tokenizer.texts_to_matrix(text)  # преобразуем исходный текст в массив OHE\n",
    "n = data.shape[0] - inp_chars  # так как мы предсказываем по трем символам - четвертый\n",
    "\n",
    "X = np.array([data[i:i + inp_chars, :] for i in range(n)])\n",
    "Y = data[inp_chars:]  # предсказание следующего символа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6307, 34)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 128)               20864     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 34)                4386      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,250\n",
      "Trainable params: 25,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input((inp_chars,\n",
    "                 num_characters)))  # при тренировке в рекуррентные модели keras подается сразу вся последовательность, поэтому в input теперь два числа. 1-длина последовательности, 2-размер OHE\n",
    "model.add(SimpleRNN(128, activation='tanh'))  # рекуррентный слой на 500 нейронов\n",
    "model.add(Dense(num_characters, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "197/197 [==============================] - 2s 2ms/step - loss: 2.9841 - accuracy: 0.1819\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 2.6521 - accuracy: 0.2595\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 2.4593 - accuracy: 0.3069\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 2.3222 - accuracy: 0.3401\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 2.2240 - accuracy: 0.3576\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 2.1536 - accuracy: 0.3782\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 2.0929 - accuracy: 0.3852\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.0442 - accuracy: 0.3982\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 2.0031 - accuracy: 0.4071\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.9633 - accuracy: 0.4145\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.9265 - accuracy: 0.4204\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.8880 - accuracy: 0.4363\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.8477 - accuracy: 0.4442\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.8108 - accuracy: 0.4534\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.7714 - accuracy: 0.4658\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.7320 - accuracy: 0.4731\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.6903 - accuracy: 0.4914\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.6493 - accuracy: 0.5037\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.6150 - accuracy: 0.5077\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.5794 - accuracy: 0.5218\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.5324 - accuracy: 0.5409\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.4966 - accuracy: 0.5480\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.4578 - accuracy: 0.5572\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.4172 - accuracy: 0.5751\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.3843 - accuracy: 0.5836\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.3475 - accuracy: 0.5915\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.3044 - accuracy: 0.6078\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.2657 - accuracy: 0.6156\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.2429 - accuracy: 0.6201\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.1986 - accuracy: 0.6399\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.1684 - accuracy: 0.6499\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.1357 - accuracy: 0.6526\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.0983 - accuracy: 0.6666\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.0662 - accuracy: 0.6774\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.0405 - accuracy: 0.6840\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.0104 - accuracy: 0.6939\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.9836 - accuracy: 0.6988\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.7099\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.9240 - accuracy: 0.7142\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.9005 - accuracy: 0.7277\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.8741 - accuracy: 0.7312\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.8504 - accuracy: 0.7404\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.8194 - accuracy: 0.7534\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.8070 - accuracy: 0.7564\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.7784 - accuracy: 0.7667\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.7567 - accuracy: 0.7743\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.7438 - accuracy: 0.7777\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.7240 - accuracy: 0.7821\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.7916\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.7962\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.8015\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.8043\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.8110\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.8170\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.8211\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.8275\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.8281\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.8326\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.8410\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.8359\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.8421\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8438\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.8476\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.8551\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8481\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8540\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8527\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8615\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8637\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8646\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8670\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8667\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8732\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8688\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8670\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8748\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8724\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8794\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8770\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8775\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8789\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8800\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8773\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8830\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8807\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8826\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8834\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8846\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8851\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8849\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8897\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8862\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8840\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8875\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8908\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8911\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8894\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8875\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8878\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "утренним пробнемажисерии позитивноетата подождый сдотам \n"
     ]
    }
   ],
   "source": [
    "def buildPhrase(inp_str, str_len=50):\n",
    "    for i in range(str_len):\n",
    "        x = []\n",
    "        for j in range(i, i + inp_chars):\n",
    "            x.append(tokenizer.texts_to_matrix(inp_str[j]))  # преобразуем символы в One-Hot-encoding\n",
    "\n",
    "        x = np.array(x)\n",
    "        inp = x.reshape(1, inp_chars, num_characters)\n",
    "\n",
    "        pred = model.predict(inp)  # предсказываем OHE четвертого символа\n",
    "        d = tokenizer.index_word[pred.argmax(axis=1)[0]]  # получаем ответ в символьном представлении\n",
    "\n",
    "        inp_str += d  # дописываем строку\n",
    "\n",
    "    return inp_str\n",
    "\n",
    "\n",
    "res = buildPhrase(\"утренн\")\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "with open('data/text', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read()\n",
    "    texts = texts.replace('\\ufeff', '')  # убираем первый невидимый символ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('я', 21), ('притягиваю', 1), ('только', 21), ('плохое', 1), ('кому', 2), ('нужен', 2), ('с', 12), ('такой', 5), ('внешностью', 2), ('не', 91)]\n"
     ]
    }
   ],
   "source": [
    "maxWordsCount = 1000\n",
    "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
    "                      lower=True, split=' ', char_level=False)\n",
    "tokenizer.fit_on_texts([texts])\n",
    "\n",
    "dist = list(tokenizer.word_counts.items())\n",
    "print(dist[:10])\n",
    "\n",
    "data = tokenizer.texts_to_sequences([texts])\n",
    "# res = to_categorical(data[0], num_classes=maxWordsCount)\n",
    "# print(res.shape)\n",
    "res = np.array(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_words = 3\n",
    "n = res.shape[0] - inp_words\n",
    "\n",
    "X = np.array([res[i:i + inp_words] for i in range(n)])\n",
    "Y = to_categorical(res[inp_words:], num_classes=maxWordsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 256)            256000    \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 128)               49280     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1000)              129000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 434,280\n",
      "Trainable params: 434,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(maxWordsCount, 256, input_length=inp_words))\n",
    "# model.add(Input((inp_words, maxWordsCount)))\n",
    "model.add(SimpleRNN(128, activation='tanh'))\n",
    "model.add(Dense(maxWordsCount, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "52/52 [==============================] - 2s 5ms/step - loss: 6.8442 - accuracy: 0.0367\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 6.1546 - accuracy: 0.0547\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 5.7563 - accuracy: 0.0733\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 5.3005 - accuracy: 0.1304\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 4.6721 - accuracy: 0.2085\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 3.9725 - accuracy: 0.3341\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 3.2917 - accuracy: 0.4880\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 2.6899 - accuracy: 0.5889\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 2.1680 - accuracy: 0.6851\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.7303 - accuracy: 0.7626\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.3690 - accuracy: 0.8323\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.0894 - accuracy: 0.8840\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.8687 - accuracy: 0.9183\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6954 - accuracy: 0.9417\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5611 - accuracy: 0.9573\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.9712\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.9784\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.3159 - accuracy: 0.9814\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2652 - accuracy: 0.9844\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.2247 - accuracy: 0.9868\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.1932 - accuracy: 0.9856\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.1690 - accuracy: 0.9844\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.1500 - accuracy: 0.9880\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.1340 - accuracy: 0.9862\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9892\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1072 - accuracy: 0.9874\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9874\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9874\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9874\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9880\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9874\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9880\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9880\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9892\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9880\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9874\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9886\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9886\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9874\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9886\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9898\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9886\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9868\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9880\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9886\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9880\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9910\n",
      "Epoch 48/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9886\n",
      "Epoch 49/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9868\n",
      "Epoch 50/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9886\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPhrase(texts, str_len=20):\n",
    "    res = texts\n",
    "    data = tokenizer.texts_to_sequences([texts])[0]\n",
    "    for i in range(str_len):\n",
    "        # x = to_categorical(data[i: i + inp_words], num_classes=maxWordsCount)  # преобразуем в One-Hot-encoding\n",
    "        # inp = x.reshape(1, inp_words, maxWordsCount)\n",
    "        x = data[i: i + inp_words]\n",
    "        inp = np.expand_dims(x, axis=0)\n",
    "        pred = model.predict(inp)\n",
    "        indx = pred.argmax(axis=1)[0]\n",
    "        data.append(indx)\n",
    "\n",
    "        res += \" \" + tokenizer.index_word[indx]  # дописываем строку\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "позитив добавляет годы счастье вашей жизни и двигаться приверженным в конце это создают сильных можете независимо через и вы проходите в конце туннеля\n"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"позитив добавляет годы\")\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Input, Dropout, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_data_true', 'r', encoding='utf-8') as f:\n",
    "    texts_true = f.readlines()\n",
    "    texts_true[0] = texts_true[0].replace('\\ufeff', '')\n",
    "with open('data/train_data_false', 'r', encoding='utf-8') as f:\n",
    "    texts_false = f.readlines()\n",
    "    texts_false[0] = texts_false[0].replace('\\ufeff', '') #убираем первый невидимый символ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 88 172\n"
     ]
    }
   ],
   "source": [
    "texts = texts_true + texts_false\n",
    "count_true = len(texts_true)\n",
    "count_false = len(texts_false)\n",
    "total_lines = count_true + count_false\n",
    "print(count_true, count_false, total_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('думайте', 1), ('позитивно', 4), ('и', 50), ('верьте', 3), ('в', 38), ('свою', 4), ('способность', 1), ('достигать', 1), ('отличных', 1), ('результатов', 1)]\n",
      "Думайте позитивно и верьте в свою способность достигать отличных результатов. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxWordsCount = 1000\n",
    "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»', lower=True, split=' ', char_level=False)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "dist = list(tokenizer.word_counts.items())\n",
    "print(dist[:10])\n",
    "print(texts[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197  54   2 ... 199 200 201]\n",
      " [  0   4 202 ... 205   3  67]\n",
      " [206   3  67 ...   4 208 209]\n",
      " ...\n",
      " [  0  20  62 ...  53 850 851]\n",
      " [  0   0  43 ...  33   1 853]\n",
      " [  0   0   0 ...  70  65 194]]\n"
     ]
    }
   ],
   "source": [
    "max_text_len = 10\n",
    "data = tokenizer.texts_to_sequences(texts)\n",
    "data_pad = pad_sequences(data, maxlen=max_text_len)\n",
    "print(data_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('не', 1), ('и', 2), ('в', 3), ('вы', 4), ('на', 5), ('я', 6), ('а', 7), ('только', 8), ('что', 9), ('все', 10), ('это', 11), ('если', 12), ('жизнь', 13), ('просто', 14), ('с', 15), ('чем', 16), ('никогда', 17), ('чтобы', 18), ('к', 19), ('у', 20), ('больше', 21), ('себя', 22), ('то', 23), ('всегда', 24), ('вас', 25), ('меня', 26), ('за', 27), ('вам', 28), ('когда', 29), ('от', 30), ('мне', 31), ('быть', 32), ('жизни', 33), ('есть', 34), ('но', 35), ('сделать', 36), ('без', 37), ('позитивным', 38), ('никому', 39), ('как', 40), ('ты', 41), ('тем', 42), ('для', 43), ('день', 44), ('позитивное', 45), ('своих', 46), ('мы', 47), ('много', 48), ('тебя', 49), ('никто', 50), ('такой', 51), ('деньги', 52), ('денег', 53), ('позитивно', 54), ('свою', 55), ('которые', 56), ('значит', 57), ('так', 58), ('них', 59), ('мечты', 60), ('нужно', 61), ('того', 62), ('ничего', 63), ('лучше', 64), ('надо', 65), ('верьте', 66), ('понедельник', 67), ('живи', 68), ('позволяйте', 69), ('хорошее', 70), ('можете', 71), ('ваши', 72), ('других', 73), ('делай', 74), ('тебе', 75), ('можешь', 76), ('успеха', 77), ('ваша', 78), ('стоит', 79), ('себе', 80), ('своей', 81), ('их', 82), ('позитив', 83), ('свои', 84), ('о', 85), ('энергию', 86), ('более', 87), ('делать', 88), ('по', 89), ('или', 90), ('нет', 91), ('кто', 92), ('во', 93), ('успеху', 94), ('пусть', 95), ('опасно', 96), ('равно', 97), ('ни', 98), ('же', 99), ('сама', 100), ('болезней', 101), ('подняться', 102), ('жизнью', 103), ('времена', 104), ('величайшим', 105), ('вашей', 106), ('продолжайте', 107), ('двигаться', 108), ('конце', 109), ('сильных', 110), ('людей', 111), ('свет', 112), ('может', 113), ('до', 114), ('настроены', 115), ('иметь', 116), ('хорошую', 117), ('строите', 118), ('эту', 119), ('позитивного', 120), ('отношения', 121), ('чудеса', 122), ('способности', 123), ('достичь', 124), ('оставайся', 125), ('доверяй', 126), ('твой', 127), ('вещи', 128), ('приносят', 129), ('радость', 130), ('верь', 131), ('опыт', 132), ('отношение', 133), ('собираетесь', 134), ('выбор', 135), ('позитивный', 136), ('всю', 137), ('свое', 138), ('время', 139), ('обиды', 140), ('думаете', 141), ('потому', 142), ('каждый', 143), ('позитивные', 144), ('позитивной', 145), ('можем', 146), ('позитивную', 147), ('станет', 148), ('контролируете', 149), ('будьте', 150), ('возможности', 151), ('таланты', 152), ('были', 153), ('из', 154), ('два', 155), ('должен', 156), ('превращай', 157), ('которую', 158), ('стать', 159), ('делает', 160), ('человека', 161), ('нужны', 162), ('либо', 163), ('всем', 164), ('настроем', 165), ('почему', 166), ('позитивность', 167), ('самое', 168), ('главное', 169), ('один', 170), ('сейчас', 171), ('вокруг', 172), ('бы', 173), ('кому', 174), ('нужен', 175), ('внешностью', 176), ('могу', 177), ('точно', 178), ('поэтому', 179), ('даже', 180), ('такая', 181), ('любит', 182), ('плохая', 183), ('мой', 184), ('этого', 185), ('тут', 186), ('этих', 187), ('тогда', 188), ('болею', 189), ('бывает', 190), ('хоть', 191), ('бывают', 192), ('заработать', 193), ('платить', 194), ('богатство', 195), ('зависти', 196), ('думайте', 197), ('способность', 198), ('достигать', 199), ('отличных', 200), ('результатов', 201), ('лучший', 202), ('ответ', 203), ('проблемы', 204), ('возникли', 205), ('смогли', 206), ('постели', 207), ('супер', 208), ('герой', 209), ('твои', 210), ('утренние', 211), ('мысли', 212), ('задают', 213), ('тон', 214), ('всей', 215), ('твоей', 216), ('неделе', 217), ('увидеть', 218), ('становишься', 219), ('сильнее', 220), ('живешь', 221), ('счастливой', 222), ('полноценной', 223), ('утренним', 224), ('проблемам', 225), ('помешать', 226), ('успешным', 227), ('тяжелые', 228), ('часто', 229), ('приводят', 230), ('моментам', 231), ('трудности', 232), ('концов', 233), ('создают', 234), ('независимо', 235), ('через', 236), ('проходите', 237), ('туннеля', 238), ('показаться', 239), ('добраться', 240), ('него', 241), ('сложно', 242), ('сможете', 243), ('говорите', 244), ('хочу', 245), ('реальность', 246), ('принятие', 247), ('ко', 248), ('всему', 249), ('происходящему', 250), ('творить', 251), ('настроение', 252), ('добавляет', 253), ('годы', 254), ('весну', 255), ('вашему', 256), ('шагу', 257), ('искорку', 258), ('ваших', 259), ('глазах', 260), ('природные', 261), ('важны', 262), ('многого', 263), ('целеустремленность', 264), ('окружите', 265), ('позитивными', 266), ('людьми', 267), ('верят', 268), ('поддерживают', 269), ('идеи', 270), ('прости', 271), ('инвестируй', 272), ('своим', 273), ('инстинктам', 274), ('позволяй', 275), ('другим', 276), ('испортить', 277), ('люби', 278), ('иногда', 279), ('лучшее', 280), ('думать', 281), ('удивляться', 282), ('воображать', 283), ('зацикливаться', 284), ('дыши', 285), ('получится', 286), ('лучшему', 287), ('учись', 288), ('приобретай', 289), ('читай', 290), ('впитывай', 291), ('меняйся', 292), ('трансформируйся', 293), ('связывай', 294), ('защищай', 295), ('обещай', 296), ('докажи', 297), ('критикуй', 298), ('поощряй', 299), ('возьми', 300), ('дай', 301), ('увидь', 302), ('почувствуй', 303), ('мечтай', 304), ('достаточно', 305), ('услышать', 306), ('слушай', 307), ('расскажи', 308), ('покажи', 309), ('преданность', 310), ('вера', 311), ('важно', 312), ('добиться', 313), ('настроя', 314), ('благодарного', 315), ('определит', 316), ('прожить', 317), ('заключается', 318), ('том', 319), ('обнадеживающим', 320), ('выбирая', 321), ('оставшуюся', 322), ('тратьте', 323), ('гнев', 324), ('сожаления', 325), ('беспокойства', 326), ('слишком', 327), ('коротка', 328), ('несчастной', 329), ('выходите', 330), ('пределы', 331), ('возможностей', 332), ('намного', 333), ('способны', 334), ('большего', 335), ('знаете', 336), ('потенциала', 337), ('кажется', 338), ('вряд', 339), ('ли', 340), ('узнаете', 341), ('весь', 342), ('свой', 343), ('потенциал', 344), ('будете', 345), ('бросать', 346), ('вызов', 347), ('словно', 348), ('твоя', 349), ('началась', 350), ('посмотрите', 351), ('произойдут', 352), ('становится', 353), ('легче', 354), ('прекраснее', 355), ('видим', 356), ('добро', 357), ('людях', 358), ('беру', 359), ('негативы', 360), ('превращаю', 361), ('держись', 362), ('лучшей', 363), ('приверженным', 364), ('стремлению', 365), ('реализовать', 366), ('жить', 367), ('негативным', 368), ('умом', 369), ('положительный', 370), ('результат', 371), ('позитива', 372), ('всего', 373), ('остального', 374), ('отшутиться', 375), ('привнести', 376), ('нашу', 377), ('повседневную', 378), ('будем', 379), ('улыбаться', 380), ('разговаривать', 381), ('незнакомцами', 382), ('заменять', 383), ('рукопожатия', 384), ('объятиями', 385), ('звонить', 386), ('друзьям', 387), ('сказать', 388), ('им', 389), ('любим', 390), ('меньше', 391), ('реагируете', 392), ('негативных', 393), ('сфокусируйтесь', 394), ('сторонах', 395), ('слабостях', 396), ('сосредоточьтесь', 397), ('личности', 398), ('репутации', 399), ('благословениях', 400), ('несчастьях', 401), ('позитивны', 402), ('каждой', 403), ('идеей', 404), ('питающей', 405), ('подумайте', 406), ('планируете', 407), ('подойдите', 408), ('этому', 409), ('оптимизмом', 410), ('оставайтесь', 411), ('позитиве', 412), ('уникальны', 413), ('разные', 414), ('идти', 415), ('стопам', 416), ('напоминайте', 417), ('делают', 418), ('остальные', 419), ('должны', 420), ('развивать', 421), ('даны', 422), ('старайтесь', 423), ('хорошие', 424), ('дни', 425), ('великими', 426), ('взять', 427), ('положительное', 428), ('тех', 429), ('дней', 430), ('чувствуете', 431), ('хорошо', 432), ('человеком', 433), ('вперед', 434), ('просыпаетесь', 435), ('варианта', 436), ('положительным', 437), ('отрицательным', 438), ('оптимистом', 439), ('пессимистом', 440), ('практически', 441), ('невозможного', 442), ('этом', 443), ('мире', 444), ('сосредоточитесь', 445), ('цели', 446), ('сохраните', 447), ('настрой', 448), ('мгновение', 449), ('отвлекись', 450), ('проблем', 451), ('сосредоточься', 452), ('положительных', 453), ('возможностях', 454), ('подумай', 455), ('победители', 456), ('преддверии', 457), ('мероприятия', 458), ('имеют', 459), ('привычку', 460), ('выдвигать', 461), ('собственные', 462), ('ожидания', 463), ('работай', 464), ('усердно', 465), ('ради', 466), ('чего', 467), ('хочешь', 468), ('оно', 469), ('придет', 470), ('боя', 471), ('сильным', 472), ('смелым', 473), ('зная', 474), ('задумал', 475), ('критикует', 476), ('продолжай', 477), ('верить', 478), ('самая', 479), ('большая', 480), ('стена', 481), ('та', 482), ('своем', 483), ('уме', 484), ('своему', 485), ('разуму', 486), ('отговорить', 487), ('обманом', 488), ('заставить', 489), ('сдаться', 490), ('ему', 491), ('препятствием', 492), ('вашем', 493), ('пути', 494), ('ничто', 495), ('счастливее', 496), ('счастливое', 497), ('сердце', 498), ('скажите', 499), ('сделайте', 500), ('нечто', 501), ('желая', 502), ('помочь', 503), ('ситуации', 504), ('жаловаться', 505), ('мозги', 506), ('изменения', 507), ('рост', 508), ('изменений', 509), ('роста', 510), ('фокусируйтесь', 511), ('негативе', 512), ('смотрите', 513), ('счастье', 514), ('боль', 515), ('печаль', 516), ('слезы', 517), ('бежишь', 518), ('бежит', 519), ('тобой', 520), ('будь', 521), ('смейся', 522), ('над', 523), ('пытайся', 524), ('улучшиться', 525), ('всё', 526), ('негативное', 527), ('идеален', 528), ('вот', 529), ('карандашей', 530), ('ластики', 531), ('побеждает', 532), ('мудрость', 533), ('смотреть', 534), ('будущее', 535), ('прошлое', 536), ('якорь', 537), ('глубине', 538), ('своего', 539), ('сердца', 540), ('суждено', 541), ('совершать', 542), ('великие', 543), ('дела', 544), ('рождаются', 545), ('убеждений', 546), ('одна', 547), ('вещь', 548), ('раз', 549), ('сначала', 550), ('начинай', 551), ('ограничены', 552), ('раздвинуть', 553), ('границы', 554), ('наших', 555), ('ограничений', 556), ('будет', 557), ('вашим', 558), ('вторым', 559), ('именем', 560), ('щитом', 561), ('который', 562), ('защитит', 563), ('стрелы', 564), ('негатива', 565), ('увидите', 566), ('препятствия', 567), ('мышление', 568), ('визуализация', 569), ('моего', 570), ('моими', 571), ('ключами', 572), ('действие', 573), ('сочетании', 574), ('мышлением', 575), ('приводит', 576), ('создать', 577), ('радугу', 578), ('солнечный', 579), ('дождь', 580), ('было', 581), ('радуги', 582), ('худшие', 583), ('могут', 584), ('лучшими', 585), ('хорошим', 586), ('притягиваю', 587), ('плохое', 588), ('обязательно', 589), ('обманут', 590), ('рискнешь', 591), ('высунуться', 592), ('добром', 593), ('кончиться', 594), ('говорила', 595), ('новое', 596), ('неизвестное', 597), ('сделал', 598), ('повезет', 599), ('этим', 600), ('поделать', 601), ('старался', 602), ('судьбы', 603), ('уйдешь', 604), ('повезло', 605), ('родиться', 606), ('бедной', 607), ('семье', 608), ('умру', 609), ('нищим', 610), ('получиться', 611), ('путаю', 612), ('бестолковый', 613), ('выиграть', 614), ('можно', 615), ('пытаться', 616), ('страшная', 617), ('нужна', 618), ('везет', 619), ('память', 620), ('неудачник', 621), ('публично', 622), ('выступить', 623), ('мое', 624), ('карма', 625), ('делал', 626), ('возраст', 627), ('позволяет', 628), ('сяду', 629), ('руль', 630), ('смертельно', 631), ('доверяю', 632), ('понадеешься', 633), ('подведут', 634), ('жизненных', 635), ('препятствий', 636), ('преодолеть', 637), ('уж', 638), ('начинать', 639), ('выздороветь', 640), ('никакие', 641), ('лекарства', 642), ('помогут', 643), ('болячку', 644), ('накликала', 645), ('лишний', 646), ('вес', 647), ('уйдет', 648), ('пробовать', 649), ('толку', 650), ('медитаций', 651), ('потерянное', 652), ('возрастом', 653), ('болячки', 654), ('усиливаются', 655), ('увеличиваются', 656), ('врачам', 657), ('попади', 658), ('сразу', 659), ('найдут', 660), ('кучу', 661), ('врач', 662), ('сможет', 663), ('вылечить', 664), ('мою', 665), ('болезнь', 666), ('хронических', 667), ('еще', 668), ('избавлялся', 669), ('приговор', 670), ('внутреннюю', 671), ('вернешь', 672), ('любят', 673), ('мои', 674), ('дети', 675), ('звонят', 676), ('плохо', 677), ('чувствую', 678), ('позволить', 679), ('фрукты', 680), ('здоровое', 681), ('питание', 682), ('сильно', 683), ('дорого', 684), ('пить', 685), ('воды', 686), ('вредно', 687), ('вчера', 688), ('телевизору', 689), ('показывали', 690), ('мужчины', 691), ('рано', 692), ('поздно', 693), ('изменяют', 694), ('муж', 695), ('держать', 696), ('жену', 697), ('строгости', 698), ('парням', 699), ('одно', 700), ('раньше', 701), ('порядочных', 702), ('девушек', 703), ('осталось', 704), ('доступные', 705), ('свистни', 706), ('койку', 707), ('прыгают', 708), ('любовь', 709), ('фильмах', 710), ('книжках', 711), ('прагматично', 712), ('пожениться', 713), ('начинаются', 714), ('ссора', 715), ('выросла', 716), ('отца', 717), ('дедушки', 718), ('ребенка', 719), ('выращу', 720), ('мужика', 721), ('первым', 722), ('подойду', 723), ('мужской', 724), ('поступок', 725), ('коленях', 726), ('приползет', 727), ('женщина', 728), ('браке', 729), ('следит', 730), ('собой', 731), ('женщины', 732), ('стервы', 733), ('женщинам', 734), ('подавай', 735), ('шопинг', 736), ('блондинки', 737), ('пустоголовые', 738), ('мужики', 739), ('бесчувственные', 740), ('полюбят', 741), ('карьерной', 742), ('лестнице', 743), ('пробиться', 744), ('двигают', 745), ('сто', 746), ('пядей', 747), ('лбу', 748), ('начальник', 749), ('похвалит', 750), ('работе', 751), ('инициатива', 752), ('наказуема', 753), ('бери', 754), ('лишнего', 755), ('подводи', 756), ('коллег', 757), ('нельзя', 758), ('коллективе', 759), ('самым', 760), ('умным', 761), ('работа', 762), ('волк', 763), ('лес', 764), ('убежит', 765), ('последний', 766), ('момент', 767), ('хороших', 768), ('начальников', 769), ('признавайся', 770), ('ошибках', 771), ('накажут', 772), ('сиди', 773), ('помалкивай', 774), ('пока', 775), ('лично', 776), ('поименно', 777), ('прямо', 778), ('спросили', 779), ('помогай', 780), ('добру', 781), ('приведет', 782), ('виноватым', 783), ('будешь', 784), ('любое', 785), ('сказанное', 786), ('слово', 787), ('против', 788), ('обернется', 789), ('полно', 790), ('молодых', 791), ('успешных', 792), ('работать', 793), ('этой', 794), ('профессии', 795), ('столько', 796), ('лет', 797), ('работу', 798), ('устроиться', 799), ('3', 800), ('копейки', 801), ('зато', 802), ('раза', 803), ('месяц', 804), ('огромные', 805), ('наживают', 806), ('воровством', 807), ('честные', 808), ('большими', 809), ('добыты', 810), ('обманным', 811), ('путем', 812), ('получку', 813), ('попотеть', 814), ('получено', 815), ('быстро', 816), ('мигом', 817), ('теряется', 818), ('зря', 819), ('говорят', 820), ('бесплатный', 821), ('сыр', 822), ('мышеловке', 823), ('особняки', 824), ('вертолеты', 825), ('воров', 826), ('помощь', 827), ('монетой', 828), ('бескорыстно', 829), ('благотворительность', 830), ('богатых', 831), ('куры', 832), ('клюют', 833), ('помогают', 834), ('умный', 835), ('бедный', 836), ('появляются', 837), ('начинаешь', 838), ('транжирить', 839), ('зло', 840), ('бедность', 841), ('порок', 842), ('добра', 843), ('доведет', 844), ('большие', 845), ('честными', 846), ('портят', 847), ('имеет', 848), ('очень', 849), ('черствеет', 850), ('душа', 851), ('миллион', 852), ('хватит', 853)]\n"
     ]
    }
   ],
   "source": [
    "print( list(tokenizer.word_index.items()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 10) (172, 2)\n"
     ]
    }
   ],
   "source": [
    "X = data_pad\n",
    "Y = np.array([[1, 0]]*count_true + [[0, 1]]*count_false)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 128)           128000    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 10, 128)           99072     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 64)                37248     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,450\n",
      "Trainable params: 264,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(maxWordsCount, 128, input_length = max_text_len))\n",
    "# model.add(LSTM(128, return_sequences=True))\n",
    "# model.add(LSTM(64))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 5s 15ms/step - loss: 0.6950 - accuracy: 0.4419\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6914 - accuracy: 0.5872\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6879 - accuracy: 0.6047\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6843 - accuracy: 0.6802\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6804 - accuracy: 0.7035\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6760 - accuracy: 0.7209\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6706 - accuracy: 0.7558\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6639 - accuracy: 0.7907\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6550 - accuracy: 0.8488\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6441 - accuracy: 0.8779\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6290 - accuracy: 0.8895\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6096 - accuracy: 0.9186\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5829 - accuracy: 0.9477\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5498 - accuracy: 0.9477\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5064 - accuracy: 0.9302\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4579 - accuracy: 0.9302\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4027 - accuracy: 0.9302\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3471 - accuracy: 0.9244\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3017 - accuracy: 0.9360\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2600 - accuracy: 0.9419\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2259 - accuracy: 0.9477\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1961 - accuracy: 0.9477\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1724 - accuracy: 0.9477\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1440 - accuracy: 0.9651\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1229 - accuracy: 0.9651\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1048 - accuracy: 0.9767\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0882 - accuracy: 0.9767\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0750 - accuracy: 0.9826\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0612 - accuracy: 0.9826\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0513 - accuracy: 0.9826\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0415 - accuracy: 0.9942\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0358 - accuracy: 0.9942\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0291 - accuracy: 0.9942\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0247 - accuracy: 0.9942\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9942\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "def sequence_to_text(list_of_indices):\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['вы', 'лучший', 'ответ', 'на', 'проблемы']\n"
     ]
    }
   ],
   "source": [
    "t = \"Вы — лучший ответ на проблемы\".lower()\n",
    "data = tokenizer.texts_to_sequences([t])\n",
    "data_pad = pad_sequences(data, maxlen=max_text_len)\n",
    "print( sequence_to_text(data[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 612ms/step\n",
      "[[0.98498803 0.01501196]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(data_pad)\n",
    "print(res, np.argmax(res), sep='\\n')\n",
    "# 3 выведенное положительный(0), или отрицательный(1) текст."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
